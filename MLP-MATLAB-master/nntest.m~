clear

addpath('./NN');
addpath('./mnistHelper');
addpath('./data');

load_data;

epochs = 1;
batchsize = 250;
learning_rate = 1e-3;
iters_per_epoch = 1000;
pcorr = zeros(1,epochs);



smooth_loss = log(10);

% ~ 98 % correct
nodes = [8 16]; 
pcorr_max = zeros(1,length(nodes));
figure(4)
hold on

%Empty container to store results and training weights
AllContainers = containers.Map(1, 1, 'UniformValues', false);
remove(AllContainers,1);


for i = 1:length(nodes)
    %Temp storage for trained weights for this topology
    Wlayer1 = {};
    Wlayer3 = {};

    nn = Network(batchsize);
    nn.layers{1} = Linear(28 * 28, nodes(i), batchsize);
    nn.layers{2} = ReLU(nodes(i), nodes(i), batchsize);
    nn.layers{3} = Linear(nodes(i), 10, batchsize);
    nn.layers{4} = Softmax(10, 10, batchsize);

    %keep track of max accuracy
    maxAccuracy = 0;

    for e=1:1:epochs

        fprintf('Epoch %d...\n', e);

        for ii=1:1:iters_per_epoch

            nn.train(train_images, train_labels, learning_rate);
            smooth_loss = [smooth_loss smooth_loss(end) * 0.99 + 0.01 * nn.loss/batchsize];

        end

        nn.test(test_images, test_labels);

        pcorr(e) = nn.percent_correct;

        %If we have a new best accuracy, store it's weights
        if pcorr(e) > maxAccuracy
            maxAccuracy = pcorr(e);

            Wlayer1 = nn.layers{1}.W;
            Wlayer3 = nn.layers{3}.W;
        end



    %     figure();
    %     plot(smooth_loss);
    %     drawnow

    end
    pcorr_max(i) = max(pcorr);
    scatter(nodes(i),pcorr_max(i))

    % Store best trained weights and best accuracy   
    keySet = {'Accuracy', 'Layer1Weights', 'Layer2Weights'};
    valueSet = {pcorr(e), Wlayer1, Wlayer3};
    topologyContainer = containers.Map(keySet, valueSet, 'UniformValues', false);
    
    AllContainers(nodes(i)) = topologyContainer;

end

keys = keys(AllContainers);
for i = 1:length(keys)
    printBuffer = ['Number of nodes: ', keys(i, 0)];
    disp(printBuffer);
end

hold off